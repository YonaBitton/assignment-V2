# assignment-Levontin
# ğŸ›’ Product Catalog Pipeline

An intelligent product catalog management system that extracts, validates, and normalizes product data from multiple sources (CSV & unstructured text files) using OpenAI, then exposes them through an interactive chatbot interface.

---

## âœ¨ Features

- **Multi-format Data Ingestion** â€” Load product data from structured CSV files and unstructured TXT files
- **AI-Powered Extraction** â€” GPT-based extraction from free-form text (configurable in `configs/base.yaml`)
- **Config-Driven Pipeline** â€” Centralized OpenAI, validation, and export settings
- **Data Validation** â€” Automatic validation rules (price > 0, allowed categories, required fieldsâ€¦)
- **Normalized Output** â€” Export clean, structured data (JSON + CSV)
- **Interactive Chatbot UI** â€” Ask questions in natural language about catalog products

---

## ğŸ“ Project Structure
```
assignment-Levontin/
â”œâ”€â”€ .env                      # Local environment variables (ignored)
â”œâ”€â”€ .env.example              # Template for .env
â”œâ”€â”€ configs/
â”‚   â”œâ”€â”€ .gitkeep
â”‚   â””â”€â”€ base.yaml             # Main config: models, validation, exportâ€¦
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ fiches_produit_csv/   # Raw CSV product files
â”‚   â””â”€â”€ fiches_produit_txt/   # Raw TXT product files
â”œâ”€â”€ lib/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ catalog.py            # Build prompt JSON for LLM
â”‚   â”œâ”€â”€ chatbot.py            # Chatbot logic + system prompt
â”‚   â”œâ”€â”€ config.py             # Loads YAML config
â”‚   â”œâ”€â”€ constants.py          # Non-sensitive constants
â”‚   â”œâ”€â”€ data_loading.py       # Load CSV/TXT into DataFrames
â”‚   â”œâ”€â”€ export.py             # Save validated data to JSON/CSV
â”‚   â”œâ”€â”€ openai_client.py      # OpenAI client wrapper
â”‚   â”œâ”€â”€ parsing.py            # CSV normalization
â”‚   â”œâ”€â”€ paths.py              # Path utilities
â”‚   â”œâ”€â”€ text_extraction.py    # GPT-based text extraction
â”‚   â”œâ”€â”€ ui_catalog_chat.py    # Panel dashboard for chatbot
â”‚   â”œâ”€â”€ utils.py              # Helpers
â”‚   â””â”€â”€ validation.py         # Product validation rules
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ clean_assignment.ipynb  # Main notebook
â”‚   â””â”€â”€ old_nb.ipynb
â”œâ”€â”€ output_data/
â”‚   â”œâ”€â”€ products_csv/
â”‚   â”‚   â””â”€â”€ products.csv
â”‚   â””â”€â”€ products_json/
â”‚       â””â”€â”€ products.json
â”œâ”€â”€ tests/                    # (empty placeholder for now)
â”œâ”€â”€ .gitignore
â”œâ”€â”€ Makefile
â”œâ”€â”€ poetry.lock
â”œâ”€â”€ pyproject.toml
â””â”€â”€ README.md
````
---


## ğŸš€ Getting Started

### Prerequisites

- Python 3.10+
- [Poetry](https://python-poetry.org/) for dependency management
- OpenAI API key


### Installation

```bash
# Clone the repository
git clone <repo-url>
cd assignment-Levontin

# Install dependencies with Poetry
make install

# Or manually:
poetry install
```


---

## ğŸ” Environment Setup

Create a `.env` file at the project root:

```env
OPENAI_API_KEY=your-openai-api-key-here
```
Edit the example file
```bash
cp .env.example .env
```

---

## ğŸ“– Usage

### 1. Run the Notebook Pipeline

Open and run the Jupyter notebook to process the full pipeline:

```bash
poetry run jupyter lab notebooks/clean_assignment.ipynb
```

The notebook will:
1. Load products from CSV and TXT files
2. Extract structured data from text using OpenAI
3. Normalize and merge all products
4. Validate products against business rules
5. Export to `output_data/`

---

### 2. Interactive Chatbot

After processing, launch the chatbot UI to query your catalog:

```python
from lib.catalog import build_catalog_for_llm
from lib.chatbot import create_catalog_system_context
from lib.ui_catalog_chat import build_catalog_chat_dashboard

# Build context from your validated DataFrame
catalog_text = build_catalog_for_llm(df_validated)
context = create_catalog_system_context(catalog_text)

# Launch dashboard
dashboard = build_catalog_chat_dashboard(context)
dashboard
```

Ask things like:

- *Â« Quels produits y a-t-il dans la catÃ©gorie wearable ? Â»*
- *Â« Donne-moi les dÃ©tails sur la chaise de bureau Â»*
- *â€œSummarize in one sentence the office chairâ€*
- *â€œWhich products are suitable for remote work?â€*

---

## âœ… Validation Rules
Products are validated against the following rules:

| Field | Rule |
|-------|------|
| `price` | Must be a positive number |
| `category` | Must be in allowed list (furniture, electronics, wearable, etc.) |
| `product_name` | Cannot be empty |
| `description_short` | Max 280 characters |
| `in_stock` | Must be a boolean |
| `features` | If present, must be a non-empty list |

### Allowed Categories

- `furniture`
- `electronics`
- `electronics / audio`
- `electronics / lighting`
- `accessory`
- `wearable`
- `office`
- `clothing`
---

## ğŸ› ï¸ Development

### Tests (empty for now)

```bash
make test
# or
poetry run pytest
```

### Format & Lint Code

If `make` doesn't work on your environment:

```bash
poetry run pre-commit run --all-files
```

Runs ruff, codespell, nbstripout, etc.

---

## ğŸ“¦ Main Dependencies

| Package        | Purpose |
|----------------|---------|
| pandas         | Data manipulation |
| openai         | GPT API |
| panel          | Dashboard UI |
| python-dotenv  | Environment loading |
| loguru         | Logging |
| pytest         | Testing |
| pre-commit     | Code quality |

See `pyproject.toml` for the complete list.
---

## ğŸ“„ License

Project for assignment purposes.

---

## ğŸ‘¤ Author

**Yona Bitton** â€” yonabitton@gmail.com
